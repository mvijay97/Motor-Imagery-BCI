{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OVR-Gaussian.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sjk8sDe5Gj5-"},"source":["This notebook demonstrates the \"One versus the Rest\" classification paradigm for Common Spatial Patterns based classification of EEG Motor Imagery Trials. It can identify four classes of Motor Imagery - \n","* Left Hand\n","* Right Hand\n","* Tongue\n","* Foot\n","\n","Four one versus the rest classifiers, one corresponding to each class in the dataset are constructed. Test instances are classified by all four classifiers - the final decision is that of the classifier which predicts a class with the highest probability"]},{"cell_type":"code","metadata":{"id":"IBRZC7gRwEc_"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9O_FDYl5tDUr"},"source":["import numpy as np\n","import math\n","import xgboost\n","import time\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","bands = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_CckXSExHUPN"},"source":["Utility functions to read data into memory, reshape data, and reformat data to suit one versus the rest classification"]},{"cell_type":"code","metadata":{"id":"jQW5zikstI5B","executionInfo":{"status":"ok","timestamp":1609922249771,"user_tz":-330,"elapsed":966,"user":{"displayName":"Malaika Vijay 01FB16ECS189PESU CSESTUDENT","photoUrl":"","userId":"09943993467447951085"}}},"source":["def get_data(subject):\n","    \"\"\"\n","    Loads the augmented, filtered data into memory\n","\n","    Parameters: \n","    subject(int): The numeric identifier of each subject in the dataset\n","\n","    Returns:\n","    numpy.ndarray: training data\n","    numpy.ndarray: training labels\n","    numpy.ndarray: test data\n","    numpy.ndarray: test labels\n","    \"\"\"\n","\n","    X_train = np.load('/content/drive/My Drive/EEG-MI/data/filtered/aug/signals/gaussian/X0{}T.npy'.format(subject))\n","    y_train = np.load('/content/drive/My Drive/EEG-MI/data/filtered/aug/labels/gaussian/y0{}T.npy'.format(subject))\n","    X_test = np.load('/content/drive/My Drive/EEG-MI/data/filtered/X0{}E.npy'.format(subject))\n","    y_test = np.load('/content/drive/My Drive/EEG-MI/data/filtered/y0{}E.npy'.format(subject))\n","    print(type(y_train))\n","    return X_train, y_train, X_test, y_test\n","\n","def binarize_labels(y, class_1, class_2):\n","    \"\"\"\n","    Converts an array of labels into binary representation e.g. the labels 770,771 will translate to 0,1.\n","    \"\"\"\n","\n","    y_bin = []\n","    for i in y:\n","        if i == class_1:\n","            y_bin.append(0)\n","        else:\n","            y_bin.append(1)\n","    return np.array(y_bin)\n","\n","def reshape_trial_major(data):\n","    \"\"\"\n","    Reshapes data to conform to the following axis representation - (trials, frequency bands, channels, samples) \n","    e.g. a set with 20 trials, 10 frequency bands, 22 channels and 750 data points gets shaped into a matrix with dimensions (20, 10, 22, 750)\n","\n","    Parameters: \n","    data(numpy.ndarray): EEG signals with the following dimensions - (frequency bands, trials, channels, samples)\n","\n","    Returns:\n","    numpy.ndarray: EEG signals with the following dimensions - (trials, frequency bands, channels, samples)\n","    \"\"\"\n","\n","    X = []\n","    for trial in range(data.shape[1]):\n","        band_data = []\n","        for band in range(10):\n","            band_data.append(data[band][trial])\n","        X.append(band_data)\n","    return np.array(X)\n","\n","def reshape_band_major(data):\n","    \"\"\"\n","    Reshapes data to conform to the following axis representation - (frequency bands, trials, channels, samples) \n","    e.g. a set with 20 trials, 10 frequency bands, 22 channels and 750 data points gets shaped into a matrix with dimensions (10, 20, 22, 750)\n","\n","    Parameters: \n","    data(numpy.ndarray): EEG signals with the following dimensions - (trials, frequency bands, channels, samples)\n","\n","    Returns:\n","    numpy.ndarray: EEG signals with the following dimensions - (frequency bands, trials, channels, samples)\n","    \"\"\"\n","\n","    X = []\n","    for band in range(10):\n","        trial_data = []\n","        for trial in range(data.shape[0]):\n","            trial_data.append(data[trial][band])\n","        X.append(trial_data)\n","    return np.array(X)\n","\n","def get_OVR_data(y, ovr_class):\n","    \"\"\"\n","    Reformats labels such that all labels corresponding to the provided class are encoded as 1 and the rest are encoded as 0\n","\n","    Parameters:\n","    y(numpy.ndarray): labels array\n","    ovr_class: the class value to be encoded as 1\n","\n","    Returns:\n","    numpy.ndarray: One versus the rest formatted labels\n","    \"\"\"\n","    \n","    labels = []\n","    for i in y:\n","        if i == ovr_class:\n","            labels.append(1)\n","        else:\n","            labels.append(0)\n","    return np.array(labels)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xmbzoDJVHhy0"},"source":["Functions to construct the Common Spatial Patterns projection matrices and compute CSP features on input data"]},{"cell_type":"code","metadata":{"id":"m1zP0fAqu89p"},"source":["def get_CSP_mat(X,y,class1,class2):\n","    \"\"\"\n","    Generates the CSP projection matrix for the input training instances\n","\n","    Parameters:\n","    X(numpy.ndarray): Training instances corresponding to a particular frequency band\n","    y(numpy.ndarray): Training labels\n","    class1: the value of the label corresponding to the first class\n","    class2: the value of the label corresponding to the second class\n","\n","    Returns:\n","    numpy.ndarray: The CSP Projection Matrix\n","    numpy.ndarray: The sorted Eigenvalues\n","    \"\"\"\n","\n","    R1=np.zeros((22,22)) #To store the sum of the covariance matrices of class 1\n","    R2=np.zeros((22,22)) #To store the sum of the covariance matrices of class 1\n","\n","    c1=list(y).count(class1) \n","    c2=list(y).count(class2)\n","\n","    #Compute the sum of covariance matrices for each trial for each class\n","    for i in range(len(y)):\n","        temp=np.dot(X[i],np.transpose(X[i]))\n","        temp=np.divide(temp,np.trace(temp))\n","        if(y[i])==class1:\n","            R1=np.add(R1,temp)\n","        else:\n","            R2=np.add(R2,temp)\n","\n","    #Compute average covariance matrices for both classes \n","    R1=np.divide(R1,c1)\n","    R2=np.divide(R2,c2)\n","    R=np.add(R1,R2) #Composite Spatial Covariance\n","\n","    e_val,e_vec=np.linalg.eig(R)\n","    #Sort in Descending Order of eigenvalues\n","    e_val=[(e_val[i],i) for i in range(len(e_val))]\n","    e_val=list(e_val)\n","    e_val.sort(key= lambda x:x[0])\n","    e_val.reverse()\n","    args=[e_val[i][1] for i in range(22)]\n","    e_val=[e_val[i][0] for i in range(22)]\n","    e_vec=e_vec[:,args]\n","    e_val=np.diag(np.power(e_val,-0.5))\n","\n","    P=np.dot(e_val,np.transpose(e_vec))#Whitening Transformation Matrix\n","\n","    S1=np.dot(P,np.dot(R1,np.transpose(P)))\n","    S2=np.dot(P,np.dot(R2,np.transpose(P)))\n","\n","    #Simultaneous diagonalisation of S1 and S2\n","    e_val1,e_vec=np.linalg.eig(S1)\n","    e_val2,e_vec=np.linalg.eig(S2)\n","\n","    a=np.argsort(e_val1) #Sort eigenvalues \n","    W=np.dot(np.transpose(e_vec),P) #Final Projection Matrix\n","\n","    return(W,a)\n","\n","def get_CSP_band_features(data,W,a):\n","    \"\"\"\n","    Computes the log variance of the CSP transformed signals\n","\n","    Parameters: \n","    data(numpy.ndarray): The input trials corresponding to a single frequency band\n","    W(numpy.ndarray): The CSP projection matrix for this frequency band\n","    a(numpy.ndarray): The sorted Eigenvalues\n","\n","    Returns:\n","    numpy.ndarray: The log variance of the channels of CSP transformed signals corresponding to the two minimum and maximum eigenvalues\n","    \"\"\"\n","\n","    reconstructed_eeg=np.dot(W,data)\n","    sources=[reconstructed_eeg[k] for k in [a[0],a[1],a[20],a[21]]]\n","    sources_var=[]\n","    s=0\n","    for j in sources:\n","        k=np.var(j)\n","        s+=k\n","        sources_var.append(k)\n","    return(np.log(np.divide(sources_var,s)))\n","\n","def get_test_features(data, W, a):\n","    \"\"\"\n","    Generates the CSP features for all frequency bands of the input signals\n","\n","    Parameters:\n","    data(numpy.ndarray): The input trials corresponding to all frequency bands\n","    W(numpy.ndarray): The CSP projection matrix for each frequency band\n","    a(numpy.ndarray): The sorted Eigenvalues for each frequency band\n","\n","    Returns:\n","    numpy.ndarray: The log variance of the channels of CSP transformed signals corresponding to the two minimum and maximum eigenvalues for all frequency bands\n","    \"\"\"\n","    \n","    features = []\n","    for i in range(10):\n","        features.extend(get_CSP_band_features(data[i], W[i], a[i]))\n","    return np.array(features)\n","\n","def get_features(X_train, X_test, y_train):\n","    \"\"\"\n","    Computes the train and test CSP features for the input train and test signals\n","\n","    Parameters: \n","    X_train(numpy.ndarray): The input training set of trials\n","    X_test(numpy.ndarray): The input test set of trials\n","    y_train(numpy.ndarray): The labels corresponding to the training set \n","\n","    Returns:\n","    numpy.ndarray: the log variance features of the CSP transformed training signals\n","    numpy.ndarray: the log variance features of the CSP transformed test signals\n","    numpy.ndarray: the CSP Projection Matrices for each frequency band\n","    numpy.ndarray: the eigenvalues for each frequency band\n","    \"\"\"\n","\n","    W = []\n","    a = []\n","\n","    for band in range(bands):\n","        W_band, a_band = get_CSP_mat(X_train[band],y_train, 0, 1)\n","        W.append(W_band)\n","        a.append(a_band)\n","\n","    features_train = []\n","    for i in range(X_train.shape[1]):\n","        features = []\n","        for band in range(bands):\n","            features.extend(get_CSP_band_features(X_train[band][i], W[band], a[band]))\n","        features_train.append(features)\n","\n","    features_train = np.array(features_train)\n","\n","    features_test = []\n","    for i in range(X_test.shape[1]):\n","        features = []\n","        for band in range(bands):\n","            features.extend(get_CSP_band_features(X_test[band][i], W[band], a[band]))\n","        features_test.append(features)\n","\n","    features_test = np.array(features_test)\n","\n","    return(features_train, features_test, W, a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-tvPPZvyIACp"},"source":["Functions to train the one verus the rest classifiers"]},{"cell_type":"code","metadata":{"id":"dfRfF9aavFtf"},"source":["def build_OVR_clf(X_train, y_train, X_test, y_test, lr, depth, est, colsample):\n","    \"\"\"\n","    Trains a one versus the rest classifier on the provided training instances.\n","\n","    Parameters:\n","    X_train(numpy.ndarray): the training instances\n","    y_train(numpy.ndarray): the training labels\n","    X_test(numpy.ndarray): the test instancs\n","    y_test(numpy.ndarray): the test labels\n","    lr(float): learning rate of XGBoost classifier\n","    depth(int): the max depth of a tree for the XGBoost classifier\n","    est(int): number of estimators for the XGBoost classifier\n","    colsample(float): the column subsampling ratio of the XGBoost classfier\n","    \"\"\"\n","    f_train = X_train\n","    f_test = X_test\n","    l_train = y_train\n","    l_test = y_test\n","    f_train, f_test, W, a = get_features(f_train, f_test, l_train)\n","    clf = xgboost.XGBClassifier()\n","    clf = xgboost.XGBClassifier(max_depth=depth, learning_rate=lr, n_estimators=est, objective='binary:logistic', subsample=0.8, colsample_bytree=colsample, silent=True, seed=42)\n","    clf.fit(f_train, l_train)\n","    return clf, W, a\n","\n","def build_classifiers(subject, lr, depth, est, colsample):\n","    \"\"\"\n","    Constructs  4 one versus the rest classifiers, one for each class represented in the dataset\n","\n","    Parameters: \n","    subject(int): the numeric identifier of the subject\n","    lr(float): learning rate of XGBoost classifier\n","    depth(int): the max depth of a tree for the XGBoost classifier\n","    est(int): number of estimators for the XGBoost classifier\n","    cols(float): the column subsampling ratio of the XGBoost classfier\n","\n","    Returns:\n","    dict: the trained level1 and leve2 classifiers\n","    numpy.ndarray: the test instances\n","    numpy.ndarray: the test labels\n","    \"\"\"\n","    \n","    X_train, y_train, X_test, y_test = get_data(subject)\n","    models = {}\n","    labels = [769,770,771,772]\n","    for i in range(4):\n","        f_train = get_OVR_data(y_train, labels[i])\n","        clf, W, a = build_OVR_clf(X_train, f_train, X_test, y_test, lr, depth, est, colsample)\n","        models[labels[i]] = {'clf': clf, 'W':W, 'a':a}\n","\n","    return models, X_test, y_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uvv8V90vIFv8"},"source":["Functions to make predictions on test data and evaluate model performance"]},{"cell_type":"code","metadata":{"id":"o8DLtusLwGOk"},"source":["def score(labels_pred, labels_true):\n","    \"\"\"\n","    Returns the accuracy of the model \n","\n","    Parameters:\n","    labels_pred(numpy.ndarray): The predicted class labels\n","    labels_true(numpy.ndarray): The ground truth labels\n","\n","    Returns:\n","    float: the prediction accuracy\n","    \"\"\"\n","    scores = 0\n","    for i in range(len(labels_pred)):\n","        if labels_pred[i] == labels_true[i]:\n","            scores+=1\n","    return(scores/len(labels_pred))\n","\n","def predict(models, X_test, y_test):\n","    \"\"\"\n","    Uses the built models to predict class labels of test instances. Each test instances is classfied by all four one versus the rest classifiers. The final decision is that of the classifier which predicts a class with the highest probability.\n","    \n","    Parameters:\n","    models(dict): dictionary of all models\n","    X_test(numpy.ndarray): the test instances\n","    y_test(numpy.ndarrat): the labels corresponding to the test set\n","\n","    Returns:\n","    float: the prediction accuracy of the model\n","    float: the cohen kappa score of the model\n","    np.ndarray: the average precision, recall and f1 scores of the model\n","    \"\"\"\n","    labels = [769, 770, 771 ,772]\n","    X_test = reshape_trial_major(X_test)\n","    pred = []\n","  \n","    start = time.time()\n","    for i in range(len(y_test)):\n","        scores = []\n","        for label in [769, 770, 771, 772]:\n","            clf = models[label]\n","            W = clf['W']\n","            a = clf['a']\n","            sample = get_test_features(X_test[i], W, a)\n","            scores.append(clf['clf'].predict_proba([sample])[0][1])\n","        pred.append(labels[np.where(scores == np.amax(scores))[0][0]])\n","    end = time.time() - start\n","    return score(pred, y_test), cohen_kappa_score(pred, y_test), end/len(y_test), np.mean(precision_recall_fscore_support(y_test, pred)[0]), np.mean(precision_recall_fscore_support(y_test, pred)[1]), np.mean(precision_recall_fscore_support(y_test, pred)[2])          "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nVVIpOh9GBoF"},"source":["Builds the classifiers and evaluates them on each subjects data. The parameter values used for the XGBoost classifiers -\n","\n","* Max depth - 3\n","* Number of Estimator - 100\n","* Column Subsampling Ratio - 0.5"]},{"cell_type":"code","metadata":{"id":"q-oAWdRURcUV"},"source":["kappas = []\n","accs = []\n","p = []\n","r = []\n","f = []\n","for subject in range(1,10):\n","    models, X_test, y_test = build_classifiers(subject, 0.01, 3, 100, 0.5)\n","    acc, kappa, test_time, precision, recall, f1 = predict_OVR(models, X_test, y_test)\n","    kappas.append(kappa)\n","    accs.append(acc)\n","    p.append(precision)\n","    r.append(recall)\n","    f.append(f1)\n","    print(subject, kappa, acc, precision, recall, f1)\n","print(np.mean(kappas), np.mean(accs))"],"execution_count":null,"outputs":[]}]}