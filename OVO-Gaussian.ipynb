{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OVO-Gaussian.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8x3itnfXJDIv"},"source":["This notebook demonstrates the \"One versus One\" classification paradigm for Common Spatial Patterns based classification of EEG Motor Imagery Trials. It can identify four classes of Motor Imagery - \n","* Left Hand\n","* Right Hand\n","* Tongue\n","* Foot\n","\n","Binary classifiers are constructed for each pair of classes in the dataset. Trials are classified by first passing them through the \"Left hand versus Right hand\" classifier and the \"Tongue versus Foot\" classifier. The decision of these two classifiers indicates which one versus one classifier must make the final decision - if the \"Left hand versus Right hand\" classifier predicts Left hand and the \"Tongue versus Foot\" classifier predicts Tongue, then the \"Left hand versus Tongue\" classifier makes the final decision."]},{"cell_type":"code","metadata":{"id":"3ZQ4_SwEHmjb"},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d4u6X6qLHncB"},"source":["import numpy as np\n","import math\n","import xgboost\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import cohen_kappa_score\n","import time\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","bands = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sx9b9e0rIXCa"},"source":["Utility functions to read data into memory, reshape data, and reformat labels to suit one versus one rest classification"]},{"cell_type":"code","metadata":{"id":"dVT4rJH7HpW7"},"source":["def get_data(subject):\n","    \"\"\"\n","    Loads the augmented, filtered data into memory\n","\n","    Parameters: \n","    subject(int): The numeric identifier of each subject in the dataset\n","\n","    Returns:\n","    numpy.ndarray: training data\n","    numpy.ndarray: training labels\n","    numpy.ndarray: test data\n","    numpy.ndarray: test labels\n","    \"\"\"\n","\n","    X_train = np.load('/content/drive/My Drive/EEG-MI/data/filtered/aug/signals/gaussian/X0{}T.npy'.format(subject))\n","    y_train = np.load('/content/drive/My Drive/EEG-MI/data/filtered/aug/labels/gaussian/y0{}T.npy'.format(subject))\n","    X_test = np.load('/content/drive/My Drive/EEG-MI/data/filtered/X0{}E.npy'.format(subject))\n","    y_test = np.load('/content/drive/My Drive/EEG-MI/data/filtered/y0{}E.npy'.format(subject))\n","    print(type(y_train))\n","    return X_train, y_train, X_test, y_test\n","\n","def binarize_labels(y, class_1, class_2):\n","    \"\"\"\n","    Converts an array of labels into binary representation e.g. the labels 770,771 will translate to 0,1.\n","    \"\"\"\n","\n","    y_bin = []\n","    for i in y:\n","        if i == class_1:\n","            y_bin.append(0)\n","        else:\n","            y_bin.append(1)\n","    return np.array(y_bin)\n","\n","def reshape_trial_major(data):\n","    \"\"\"\n","    Reshapes data to conform to the following axis representation - (trials, frequency bands, channels, samples) \n","    e.g. a set with 20 trials, 10 frequency bands, 22 channels and 750 data points gets shaped into a matrix with dimensions (20, 10, 22, 750)\n","\n","    Parameters: \n","    data(numpy.ndarray): EEG signals with the following dimensions - (frequency bands, trials, channels, samples)\n","\n","    Returns:\n","    numpy.ndarray: EEG signals with the following dimensions - (trials, frequency bands, channels, samples)\n","    \"\"\"\n","\n","    X = []\n","    for trial in range(data.shape[1]):\n","        band_data = []\n","        for band in range(10):\n","            band_data.append(data[band][trial])\n","        X.append(band_data)\n","    return np.array(X)\n","\n","def reshape_band_major(data):\n","    \"\"\"\n","    Reshapes data to conform to the following axis representation - (frequency bands, trials, channels, samples) \n","    e.g. a set with 20 trials, 10 frequency bands, 22 channels and 750 data points gets shaped into a matrix with dimensions (10, 20, 22, 750)\n","\n","    Parameters: \n","    data(numpy.ndarray): EEG signals with the following dimensions - (trials, frequency bands, channels, samples)\n","\n","    Returns:\n","    numpy.ndarray: EEG signals with the following dimensions - (frequency bands, trials, channels, samples)\n","    \"\"\"\n","\n","    X = []\n","    for band in range(10):\n","        trial_data = []\n","        for trial in range(data.shape[0]):\n","            trial_data.append(data[trial][band])\n","        X.append(trial_data)\n","    return np.array(X)\n","\n","def get_two_class_data(X_train, y_train, X_test, y_test, class_1, class_2):\n","    \"\"\"\n","    Collects trials corresponding to two specified classes\n","\n","    Parameters:\n","    X_train(numpy.ndarray): training data in band major format\n","    y_train(numpy.ndarray): labels corresponding to training data trials\n","    X_test(numpy.ndarray): testing data in band major format\n","    y_test(numpy.ndarray): labels corresponding to testing data trials \n","\n","    Returns:\n","    numpy.ndarray: training instances belonging to the two specified classes in band major format\n","    numpy.ndarray: binary training labels corresponding to the filtered training instances\n","    \"\"\"\n","\n","    X_train = reshape_trial_major(X_train)\n","    train = np.array([X_train[i] for i in range(len(y_train)) if y_train[i] in [class_1, class_2]])\n","    train = reshape_band_major(train)\n","    train_labels = [i for i in y_train if i in [class_1, class_2]]\n","\n","    X_test = reshape_trial_major(X_test)\n","    test = np.array([X_test[i] for i in range(len(y_test)) if y_test[i] in [class_1, class_2]])\n","    test = reshape_band_major(test)\n","    test_labels = [i for i in y_test if i in [class_1, class_2]]\n","\n","    return(train, binarize_labels(train_labels, class_1, class_2), test, binarize_labels(test_labels, class_1, class_2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VqnjOhSImWw"},"source":["Functions to construct the Common Spatial Patterns projection matrices and compute CSP features on input data"]},{"cell_type":"code","metadata":{"id":"jjga7k5fIds3"},"source":["def get_CSP_mat(X,y,class1,class2):\n","    \"\"\"\n","    Generates the CSP projection matrix for the input training instances\n","\n","    Parameters:\n","    X(numpy.ndarray): Training instances corresponding to a particular frequency band\n","    y(numpy.ndarray): Training labels\n","    class1: the value of the label corresponding to the first class\n","    class2: the value of the label corresponding to the second class\n","\n","    Returns:\n","    numpy.ndarray: The CSP Projection Matrix\n","    numpy.ndarray: The sorted Eigenvalues\n","    \"\"\"\n","\n","    R1=np.zeros((22,22)) #To store the sum of the covariance matrices of class 1\n","    R2=np.zeros((22,22)) #To store the sum of the covariance matrices of class 1\n","\n","    c1=list(y).count(class1) \n","    c2=list(y).count(class2)\n","\n","    #Compute the sum of covariance matrices for each trial for each class\n","    for i in range(len(y)):\n","        temp=np.dot(X[i],np.transpose(X[i]))\n","        temp=np.divide(temp,np.trace(temp))\n","        if(y[i])==class1:\n","            R1=np.add(R1,temp)\n","        else:\n","            R2=np.add(R2,temp)\n","\n","    #Compute average covariance matrices for both classes \n","    R1=np.divide(R1,c1)\n","    R2=np.divide(R2,c2)\n","    R=np.add(R1,R2) #Composite Spatial Covariance\n","\n","    e_val,e_vec=np.linalg.eig(R)\n","    #Sort in Descending Order of eigenvalues\n","    e_val=[(e_val[i],i) for i in range(len(e_val))]\n","    e_val=list(e_val)\n","    e_val.sort(key= lambda x:x[0])\n","    e_val.reverse()\n","    args=[e_val[i][1] for i in range(22)]\n","    e_val=[e_val[i][0] for i in range(22)]\n","    e_vec=e_vec[:,args]\n","    e_val=np.diag(np.power(e_val,-0.5))\n","\n","    P=np.dot(e_val,np.transpose(e_vec))#Whitening Transformation Matrix\n","\n","    S1=np.dot(P,np.dot(R1,np.transpose(P)))\n","    S2=np.dot(P,np.dot(R2,np.transpose(P)))\n","\n","    #Simultaneous diagonalisation of S1 and S2\n","    e_val1,e_vec=np.linalg.eig(S1)\n","    e_val2,e_vec=np.linalg.eig(S2)\n","\n","    a=np.argsort(e_val1) #Sort eigenvalues \n","    W=np.dot(np.transpose(e_vec),P) #Final Projection Matrix\n","\n","    return(W,a)\n","\n","def get_CSP_band_features(data,W,a):\n","    \"\"\"\n","    Computes the log variance of the CSP transformed signals\n","\n","    Parameters: \n","    data(numpy.ndarray): The input trials corresponding to a single frequency band\n","    W(numpy.ndarray): The CSP projection matrix for this frequency band\n","    a(numpy.ndarray): The sorted Eigenvalues\n","\n","    Returns:\n","    numpy.ndarray: The log variance of the channels of CSP transformed signals corresponding to the two minimum and maximum eigenvalues\n","    \"\"\"\n","\n","    reconstructed_eeg=np.dot(W,data)\n","    sources=[reconstructed_eeg[k] for k in [a[0],a[1],a[20],a[21]]]\n","    sources_var=[]\n","    s=0\n","    for j in sources:\n","        k=np.var(j)\n","        s+=k\n","        sources_var.append(k)\n","    return(np.log(np.divide(sources_var,s)))\n","\n","def get_test_features(data, W, a):\n","    \"\"\"\n","    Generates the CSP features for all frequency bands of the input signals\n","\n","    Parameters:\n","    data(numpy.ndarray): The input trials corresponding to all frequency bands\n","    W(numpy.ndarray): The CSP projection matrix for each frequency band\n","    a(numpy.ndarray): The sorted Eigenvalues for each frequency band\n","\n","    Returns:\n","    numpy.ndarray: The log variance of the channels of CSP transformed signals corresponding to the two minimum and maximum eigenvalues for all frequency bands\n","    \"\"\"\n","    \n","    features = []\n","    for i in range(10):\n","        features.extend(get_CSP_band_features(data[i], W[i], a[i]))\n","    return np.array(features)\n","\n","def get_features(X_train, X_test, y_train):\n","    \"\"\"\n","    Computes the train and test CSP features for the input train and test signals\n","\n","    Parameters: \n","    X_train(numpy.ndarray): The input training set of trials\n","    X_test(numpy.ndarray): The input test set of trials\n","    y_train(numpy.ndarray): The labels corresponding to the training set \n","\n","    Returns:\n","    numpy.ndarray: the log variance features of the CSP transformed training signals\n","    numpy.ndarray: the log variance features of the CSP transformed test signals\n","    numpy.ndarray: the CSP Projection Matrices for each frequency band\n","    numpy.ndarray: the eigenvalues for each frequency band\n","    \"\"\"\n","\n","    W = []\n","    a = []\n","\n","    for band in range(bands):\n","        W_band, a_band = get_CSP_mat(X_train[band],y_train, 0, 1)\n","        W.append(W_band)\n","        a.append(a_band)\n","\n","    features_train = []\n","    for i in range(X_train.shape[1]):\n","        features = []\n","        for band in range(bands):\n","            features.extend(get_CSP_band_features(X_train[band][i], W[band], a[band]))\n","        features_train.append(features)\n","\n","    features_train = np.array(features_train)\n","\n","    features_test = []\n","    for i in range(X_test.shape[1]):\n","        features = []\n","        for band in range(bands):\n","            features.extend(get_CSP_band_features(X_test[band][i], W[band], a[band]))\n","        features_test.append(features)\n","\n","    features_test = np.array(features_test)\n","\n","    return(features_train, features_test, W, a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Nr3b-LqIqDH"},"source":["Functions to train the one verus one classifiers"]},{"cell_type":"code","metadata":{"id":"QMWQCxiWIEye"},"source":["def build_classifiers(subject, lr, depth, est, cols):\n","    \"\"\"\n","    Builds one versus one XGBoost classifiers for every pair of classes in the dataset\n","\n","    Parameters:\n","    subject(int): the numeric identifier of the subject\n","    lr(float): the learning rate\n","    depth(int): max depth of a tree\n","    est(int): number of estimators for the XGBoost classifier\n","    cols(float): column subsampling ratio\n","\n","    Returns:\n","    dict: the trained XGBoost classification models for every pair of classes\n","    numpy.ndarray: the test features\n","    numpy.ndarray: the test labels\n","    \"\"\"\n","\n","    X_train, y_train, X_test, y_test = get_data(subject)\n","    labels = [769,770,771,772]\n","    models = {}\n","\n","    for class_1 in range(0,3):\n","        for class_2 in range(class_1+1,4):\n","            f_train, l_train, f_test, l_test = get_two_class_data(X_train, y_train, X_test, y_test, labels[class_1], labels[class_2])\n","            f_train, f_test, W, a = get_features(f_train, f_test, l_train)\n","            clf = xgboost.XGBClassifier(max_depth=depth, learning_rate=lr, n_estimators=est, objective='binary:logistic', subsample=0.8, colsample_bytree=cols, silent=True)\n","            clf.fit(f_train, l_train)\n","            models[(labels[class_1], labels[class_2])] = {'clf': clf, 'W': W, 'a': a}\n","    return models, X_test, y_test\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"27IWs5euI4MN"},"source":["Functions to make predictions on test data and evaluate model performance"]},{"cell_type":"code","metadata":{"id":"7v2nFwowJYiJ"},"source":["def score(labels_pred, labels_true):\n","    \"\"\"\n","    Returns the accuracy of the model \n","\n","    Parameters:\n","    labels_pred(numpy.ndarray): The predicted class labels\n","    labels_true(numpy.ndarray): The ground truth labels\n","\n","    Returns:\n","    float: the prediction accuracy\n","    \"\"\"\n","    scores = 0\n","    for i in range(len(labels_pred)):\n","        if labels_pred[i] == labels_true[i]:\n","            scores+=1\n","    return(scores/len(labels_pred))\n","\n","def predict(models, X_test, y_test):\n","    \"\"\"\n","    Uses the built models to predict class labels of test instances. The Left versus Right classifier and Tongue versus Foot classifiers are first\n","    employed. The prediction of these two classifiers decides which one verus one classifier to invoke for the final decision. For example, if the \n","    Left verus Rigth classifier predicts Left, and the Tongue versus Foot classifier predicts Tongue, the Left verus Tongue classifier is then invoked\n","    to make the final decision.\n","\n","    Parameters:\n","    models(dict): dictionary of all one versus one models\n","    X_test(numpy.ndarray): the test instances\n","    y_test(numpy.ndarrat): the labels corresponding to the test set\n","\n","    Returns:\n","    float: the prediction accuracy of the model\n","    float: the cohen kappa score of the model\n","    np.ndarray: the average precision, recall and f1 scores of the model\n","    \"\"\"\n","\n","    X_test = reshape_trial_major(X_test)\n","    pred = []\n","    start = time.time()\n","    for i in range(len(y_test)):\n","        clf_LR = models[(769,770)]\n","        clf_TF = models[(771,772)]\n","        sample_LR = get_test_features(X_test[i], clf_LR['W'], clf_LR['a'])\n","        sample_TF = get_test_features(X_test[i], clf_TF['W'], clf_TF['a'])\n","        pred_LR = clf_LR['clf'].predict([sample_LR])[0]\n","        pred_TF = clf_TF['clf'].predict([sample_TF])[0]\n","\n","        LR_label = 769 if pred_LR == 0 else 770\n","        TF_label = 771 if pred_TF == 0 else 772\n","\n","        clf_leaf = models[(LR_label,TF_label)]\n","        sample_leaf = get_test_features(X_test[i], clf_leaf['W'], clf_leaf['a'])\n","        pred_leaf = clf_leaf['clf'].predict([sample_leaf])[0]\n","\n","\n","        leaf_label = LR_label if pred_leaf == 0 else TF_label\n","        pred.append(leaf_label)\n","    end = time.time() - start\n","    return score(pred, y_test), cohen_kappa_score(pred, y_test), end/len(y_test), np.mean(precision_recall_fscore_support(y_test, pred)[2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Q-eLkvgX8aZ"},"source":["Builds the classifiers and evaluates them on each subjects data. The parameter values used for the XGBoost classifiers -\n","\n","\n","*   Max depth - 4\n","*   Number of Estimator - 500\n","*   Column Subsampling Ratio - 0.5\n","\n"]},{"cell_type":"code","metadata":{"id":"377KXudrZHLH"},"source":["# Depth:  4, Estimators:  500, Colsample:  0.5, kappa:  0.5596707818930041, accs:  0.6697530864197532\n","\n","kappas = []\n","accs = []\n","for subject in range(1,10):\n","    models, X_test, y_test = build_classifiers(subject, 0.01, 4, 500, 0.5)\n","    acc, kappa, test_time, precision_recall_f1 = predict(models, X_test, y_test)\n","    accs.append(acc)\n","    kappas.append(kappa)\n","    print(subject, kappa, acc)\n","\n","print(np.mean(kappas), np.mean(accs))\n","print(\"Depth: \", depth, \"Estimators: \",est,\"Colsample: \", cols, \"kappa: \", np.mean(kappas), \"accs: \",np.mean(accs))"],"execution_count":null,"outputs":[]}]}