{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Grouped-Gaussian.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zrYRlzXUKRhk"},"source":["This notebook demonstrates the \"Grouped\" classification paradigm for Common Spatial Patterns based classification of EEG Motor Imagery Trials. It can identify four classes of Motor Imagery - \n","* Left Hand\n","* Right Hand\n","* Tongue\n","* Foot\n","\n","Three binary classifiers are used to classify EEG trials - \n","* level 1 classifier\n","    * \"Left Hand or Right Hand\" verus \"Tongue or Foot\" - Decides whether an instance is either Left Hand or Right Hand movement OR Tongue or Foot Movement\n","\n","* level 2 classifiers\n","    * Left Hand versus Right Hand movement - Decides whether an instance is Left Hand movement or Right Hand movement\n","    * Tongue versus Foot movement - Decides whether an instances is Tongue movement or Foot movement\n","\n","The decision of the level 1 classifier indicates which level 2 classifier to invoke. If the level 1 classifier classifies a trial as Left Hand or Right Hand movement, the level 2 classifier corresponding to Left Hand versus Right Hand movement is invoked to make the final decision."]},{"cell_type":"code","metadata":{"id":"gGXUwYy2Vcut","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593456389196,"user_tz":-330,"elapsed":48505,"user":{"displayName":"Malaika Vijay 01FB16ECS189PESU CSESTUDENT","photoUrl":"","userId":"09943993467447951085"}},"outputId":"878d2424-aa82-4a33-ec91-0e79ed6a5893"},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PJ3U4SmbVkph"},"source":["import numpy as np\n","import math\n","import time\n","import xgboost\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","bands = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xJAxd_2SJ2Hk"},"source":["Utility functions to read data into memory, reshape data, and reformat labels to grouped classification"]},{"cell_type":"code","metadata":{"id":"JIFRkxSvVsbJ"},"source":["def get_data(subject):\n","    \"\"\"\n","    Loads the augmented, filtered data into memory\n","\n","    Parameters: \n","    subject(int): The numeric identifier of each subject in the dataset\n","\n","    Returns:\n","    numpy.ndarray: training data\n","    numpy.ndarray: training labels\n","    numpy.ndarray: test data\n","    numpy.ndarray: test labels\n","    \"\"\"\n","\n","    X_train = np.load('/content/drive/My Drive/EEG-MI/data/filtered/X0{}T.npy'.format(subject))\n","    y_train = np.load('/content/drive/My Drive/EEG-MI/data/filtered/y0{}T.npy'.format(subject))\n","    X_test = np.load('/content/drive/My Drive/EEG-MI/data/filtered/X0{}E.npy'.format(subject))\n","    y_test = np.load('/content/drive/My Drive/EEG-MI/data/filtered/y0{}E.npy'.format(subject))\n","    return X_train, y_train, X_test, y_test\n","\n","def binarize_labels(y, class_1, class_2):\n","    \"\"\"\n","    Converts an array of labels into binary representation e.g. the labels 770,771 will translate to 0,1.\n","    \"\"\"\n","    y_bin = []\n","    for i in y:\n","        if i == class_1:\n","            y_bin.append(0)\n","        else:\n","            y_bin.append(1)\n","    return np.array(y_bin)\n","\n","def reshape_trial_major(data):\n","    \"\"\"\n","    Reshapes data to conform to the following axis representation - (trials, frequency bands, channels, samples) \n","    e.g. a set with 20 trials, 10 frequency bands, 22 channels and 750 data points gets shaped into a matrix with dimensions (20, 10, 22, 750)\n","\n","    Parameters: \n","    data(numpy.ndarray): EEG signals with the following dimensions - (frequency bands, trials, channels, samples)\n","\n","    Returns:\n","    numpy.ndarray: EEG signals with the following dimensions - (trials, frequency bands, channels, samples)\n","    \"\"\"\n","    X = []\n","    for trial in range(data.shape[1]):\n","        band_data = []\n","        for band in range(10):\n","            band_data.append(data[band][trial])\n","        X.append(band_data)\n","    return np.array(X)\n","\n","def reshape_band_major(data):\n","    \"\"\"\n","    Reshapes data to conform to the following axis representation - (frequency bands, trials, channels, samples) \n","    e.g. a set with 20 trials, 10 frequency bands, 22 channels and 750 data points gets shaped into a matrix with dimensions (10, 20, 22, 750)\n","\n","    Parameters: \n","    data(numpy.ndarray): EEG signals with the following dimensions - (trials, frequency bands, channels, samples)\n","\n","    Returns:\n","    numpy.ndarray: EEG signals with the following dimensions - (frequency bands, trials, channels, samples)\n","    \"\"\"\n","    X = []\n","    for band in range(10):\n","        trial_data = []\n","            for trial in range(data.shape[0]):\n","                trial_data.append(data[trial][band])\n","        X.append(trial_data)\n","    return np.array(X)\n","\n","def get_two_class_data(X_train, y_train, X_test, y_test, class_1, class_2):\n","    \"\"\"\n","    Collects trials corresponding to two specified classes\n","\n","    Parameters:\n","    X_train(numpy.ndarray): training data in band major format\n","    y_train(numpy.ndarray): labels corresponding to training data trials\n","    X_test(numpy.ndarray): testing data in band major format\n","    y_test(numpy.ndarray): labels corresponding to testing data trials \n","\n","    Returns:\n","    numpy.ndarray: training instances belonging to the two specified classes in band major format\n","    numpy.ndarray: binary training labels corresponding to the filtered training instances\n","    \"\"\"\n","\n","    X_train = reshape_trial_major(X_train)\n","    train = np.array([X_train[i] for i in range(len(y_train)) if y_train[i] in [class_1, class_2]])\n","    train = reshape_band_major(train)\n","    train_labels = [i for i in y_train if i in [class_1, class_2]]\n","    \n","    X_test = reshape_trial_major(X_test)\n","    test = np.array([X_test[i] for i in range(len(y_test)) if y_test[i] in [class_1, class_2]])\n","    test = reshape_band_major(test)\n","    test_labels = [i for i in y_test if i in [class_1, class_2]]\n","\n","    return(train, binarize_labels(train_labels, class_1, class_2), test, binarize_labels(test_labels, class_1, class_2))\n","\n","def get_group_labels(y_train, y_test):\n","    \"\"\"\n","    Groups labels into two buckets - those corresponding to class 769 and 770 (assigned a class of 0), and thos belonging to class 771 and 772 (assigned\n","    a class of 1)\n","\n","    Parameters:\n","    y_train(numpy.ndarray): the labels corresponding to the training instances\n","    y_test(numpy.ndarray): the labels corresponding to the test instances\n","\n","    Returns:\n","    list: the grouped binary labels corresponding to the training instances\n","    list: the grouped binary labels corresponding to the test instances\n","    \"\"\"\n","    train_labels = []\n","    for i in y_train:\n","        if i in [769, 770]:\n","            train_labels.append(0)\n","        else:\n","            train_labels.append(1)\n","    test_labels = []\n","    for i in y_test:\n","        if i in [769, 770]:\n","            test_labels.append(0)\n","        else:\n","            test_labels.append(1)\n","    return(train_labels, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSbnjTEjJ6eu"},"source":["Functions to construct the Common Spatial Patterns projection matrices and compute CSP features on input data"]},{"cell_type":"code","metadata":{"id":"KeIc-kjRVssz","executionInfo":{"status":"ok","timestamp":1609864615330,"user_tz":-330,"elapsed":1015,"user":{"displayName":"Malaika Vijay 01FB16ECS189PESU CSESTUDENT","photoUrl":"","userId":"09943993467447951085"}}},"source":["def get_CSP_mat(X,y,class1,class2):\n","    \"\"\"\n","    Generates the CSP projection matrix for the input training instances\n","\n","    Parameters:\n","    X(numpy.ndarray): Training instances corresponding to a particular frequency band\n","    y(numpy.ndarray): Training labels\n","    class1: the value of the label corresponding to the first class\n","    class2: the value of the label corresponding to the second class\n","\n","    Returns:\n","    numpy.ndarray: The CSP Projection Matrix\n","    numpy.ndarray: The sorted Eigenvalues\n","    \"\"\"\n","\n","    R1=np.zeros((22,22)) #To store the sum of the covariance matrices of class 1\n","    R2=np.zeros((22,22)) #To store the sum of the covariance matrices of class 1\n","    \n","    c1=list(y).count(class1) \n","    c2=list(y).count(class2)\n"," \n","    #Compute the sum of covariance matrices for each trial for each class\n","    for i in range(len(y)):\n","        temp=np.dot(X[i],np.transpose(X[i]))\n","        temp=np.divide(temp,np.trace(temp))\n","        if(y[i])==class1:\n","            R1=np.add(R1,temp)\n","        else:\n","            R2=np.add(R2,temp)\n","\n","    #Compute average covariance matrices for both classes \n","    R1=np.divide(R1,c1)\n","    R2=np.divide(R2,c2)\n","    R=np.add(R1,R2) #Composite Spatial Covariance\n","    \n","    e_val,e_vec=np.linalg.eig(R)\n","    #Sort in Descending Order of eigenvalues\n","    e_val=[(e_val[i],i) for i in range(len(e_val))]\n","    e_val=list(e_val)\n","    e_val.sort(key= lambda x:x[0])\n","    e_val.reverse()\n","    args=[e_val[i][1] for i in range(22)]\n","    e_val=[e_val[i][0] for i in range(22)]\n","    e_vec=e_vec[:,args]\n","    e_val=np.diag(np.power(e_val,-0.5))\n","\n","    P=np.dot(e_val,np.transpose(e_vec))#Whitening Transformation Matrix\n","\n","    S1=np.dot(P,np.dot(R1,np.transpose(P)))\n","    S2=np.dot(P,np.dot(R2,np.transpose(P)))\n","\n","    #Simultaneous diagonalisation of S1 and S2\n","    e_val1,e_vec=np.linalg.eig(S1)\n","    e_val2,e_vec=np.linalg.eig(S2)\n","    \n","    a=np.argsort(e_val1) #Sort eigenvalues \n","    W=np.dot(np.transpose(e_vec),P) #Final Projection Matrix\n","\n","    return(W,a)\n","\n","def get_CSP_band_features(data,W,a):\n","    \"\"\"\n","    Computes the log variance of the CSP transformed signals\n","\n","    Parameters: \n","    data(numpy.ndarray): The input trials corresponding to a single frequency band\n","    W(numpy.ndarray): The CSP projection matrix for this frequency band\n","    a(numpy.ndarray): The sorted Eigenvalues\n","\n","    Returns:\n","    numpy.ndarray: The log variance of the channels of CSP transformed signals corresponding to the two minimum and maximum eigenvalues\n","    \"\"\"\n","\n","    reconstructed_eeg=np.dot(W,data)\n","    sources=[reconstructed_eeg[k] for k in [a[0],a[1],a[20],a[21]]]\n","    sources_var=[]\n","    s=0\n","    for j in sources:\n","        k=np.var(j)\n","        s+=k\n","        sources_var.append(k)\n","    return(np.log(np.divide(sources_var,s)))\n","\n","def get_test_features(data, W, a):\n","    \"\"\"\n","    Generates the CSP features for all frequency bands of the input signals\n","\n","    Parameters:\n","    data(numpy.ndarray): The input trials corresponding to all frequency bands\n","    W(numpy.ndarray): The CSP projection matrix for each frequency band\n","    a(numpy.ndarray): The sorted Eigenvalues for each frequency band\n","    \n","    Returns:\n","    numpy.ndarray: The log variance of the channels of CSP transformed signals corresponding to the two minimum and maximum eigenvalues for all frequency bands\n","    \"\"\"\n","  \n","    features = []\n","    for i in range(10):\n","        features.extend(get_CSP_band_features(data[i], W[i], a[i]))\n","    return np.array(features)\n","\n","def get_features(X_train, X_test, y_train):\n","    \"\"\"\n","    Computes the train and test CSP features for the input train and test signals\n","\n","    Parameters: \n","    X_train(numpy.ndarray): The input training set of trials\n","    X_test(numpy.ndarray): The input test set of trials\n","    y_train(numpy.ndarray): The labels corresponding to the training set \n","\n","    Returns:\n","    numpy.ndarray: the log variance features of the CSP transformed training signals\n","    numpy.ndarray: the log variance features of the CSP transformed test signals\n","    numpy.ndarray: the CSP Projection Matrices for each frequency band\n","    numpy.ndarray: the eigenvalues for each frequency band\n","    \"\"\"\n","    W = []\n","    a = []\n","\n","    for band in range(bands):\n","        W_band, a_band = get_CSP_mat(X_train[band],y_train, 0, 1)\n","        W.append(W_band)\n","        a.append(a_band)\n","\n","    features_train = []\n","    for i in range(X_train.shape[1]):\n","        features = []\n","        for band in range(bands):\n","            features.extend(get_CSP_band_features(X_train[band][i], W[band], a[band]))\n","        features_train.append(features)\n","\n","    features_train = np.array(features_train)\n","\n","    features_test = []\n","    for i in range(X_test.shape[1]):\n","        features = []\n","        for band in range(bands):\n","            features.extend(get_CSP_band_features(X_test[band][i], W[band], a[band]))\n","        features_test.append(features)\n","\n","    features_test = np.array(features_test)\n","\n","    return(features_train, features_test, W, a)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aWUw-NIZKIRR"},"source":["Functions to train the grouped classifier"]},{"cell_type":"code","metadata":{"id":"P9N5VYqVcpYO","executionInfo":{"status":"ok","timestamp":1609908510190,"user_tz":-330,"elapsed":945,"user":{"displayName":"Malaika Vijay 01FB16ECS189PESU CSESTUDENT","photoUrl":"","userId":"09943993467447951085"}}},"source":["def build_one_vs_one_clf(X_train, y_train, X_test, y_test, class_1, class_2, lr, depth, est, cols, level_1=False):\n","    \"\"\"\n","    Builds one versus one classifiers for the provided class labels. \n","\n","    Parameters:\n","    X_train(numpy.ndarray): the training instances\n","    y_train(numpy.ndarray): the training labels\n","    X_test(numpy.ndarray): the test instancs\n","    y_test(numpy.ndarray): the test labels\n","    class1(int): the class label of the first class\n","    class2(int): the class label of the second class\n","    lr(float): learning rate of XGBoost classifier\n","    depth(int): the max depth of a tree for the XGBoost classifier\n","    est(int): number of estimators for the XGBoost classifier\n","    cols(float): the column subsampling ratio of the XGBoost classfier\n","    level_1(boolean): indicator of which classification level the classifier belongs to (true if level1, false otherwise)\n","\n","    Returns:\n","    xgboost.XGBXlassifier: the trained classifier\n","    numpy.ndarray: the CSP projection matrices \n","    numpy.ndarray: the sorted eigenvalues\n","    \"\"\"\n","\n","    if not(level_1):\n","      f_train, l_train, f_test, l_test = get_two_class_data(X_train, y_train, X_test, y_test, class_1, class_2)\n","    else:\n","      f_train = X_train\n","      f_test = X_test\n","      l_train = y_train\n","      l_test = y_test\n","    f_train, f_test, W, a = get_features(f_train, f_test, l_train)\n","    clf = xgboost.XGBClassifier(max_depth=depth, learning_rate=lr, n_estimators=est, objective='binary:logistic', subsample=0.8, colsample_bytree=cols, silent=True)\n","    clf.fit(f_train, l_train)\n","    return clf, W, a\n","\n","def build_classifiers(subject, lr, depth, est, cols):\n","    \"\"\"\n","    constructs the hierarchy of one versus one classifiers. The level 1 classifier distinguishes between two classes - \"Left or Right hand\" versus \"Tongue or Foot\". The decision of this classifier indicates which level 2 classifier to invoke.\n","    If the level 1 classifier predicts \"left or right hand\" then the left hand verus right hand level 2 classifier is invoked. Else, the tongue versus foot level 2 classifier is invoked.\n","\n","    Parameters: \n","    subject(int): the numeric identifier of the subject\n","    lr(float): learning rate of XGBoost classifier\n","    depth(int): the max depth of a tree for the XGBoost classifier\n","    est(int): number of estimators for the XGBoost classifier\n","    cols(float): the column subsampling ratio of the XGBoost classfier\n","\n","    Returns:\n","    dict: the trained level1 and leve2 classifiers\n","    numpy.ndarray: the test instances\n","    numpy.ndarray: the test labels\n","    \"\"\"\n","\n","    X_train, y_train, X_test, y_test = get_data(subject)\n","    models = {}\n","    #build level one clf\n","    y_1_train, y_1_test = get_group_labels(y_train, y_test)\n","    clf, W, a = build_one_vs_one_clf(X_train, y_1_train, X_test, y_1_test, 0, 1, lr, depth, est, cols, True)\n","    models['LRvsTF'] = {'clf': clf, 'W':W, 'a':a}\n","\n","    #build LR clf\n","    clf, W, a = build_one_vs_one_clf(X_train, y_train, X_test, y_test, 769, 770, lr, depth, est, cols)\n","    models['LR'] = {'clf': clf, 'W':W, 'a':a}\n","\n","    #build TF clf\n","    clf, W, a = build_one_vs_one_clf(X_train, y_train, X_test, y_test, 771, 772, lr, depth, est, cols)\n","    models['TF'] = {'clf': clf, 'W':W, 'a':a}\n","\n","    return models, X_test, y_test"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kxcsRRdjKL-k"},"source":["Functions to make predictions on test data and evaluate model performance"]},{"cell_type":"code","metadata":{"id":"9lm-hHgGVy5e","executionInfo":{"status":"ok","timestamp":1609908622516,"user_tz":-330,"elapsed":968,"user":{"displayName":"Malaika Vijay 01FB16ECS189PESU CSESTUDENT","photoUrl":"","userId":"09943993467447951085"}}},"source":["def score(labels_pred, labels_true):\n","    \"\"\"\n","    Returns the accuracy of the model \n","\n","    Parameters:\n","    labels_pred(numpy.ndarray): The predicted class labels\n","    labels_true(numpy.ndarray): The ground truth labels\n","\n","    Returns:\n","    float: the prediction accuracy\n","    \"\"\"\n","    scores = 0\n","    for i in range(len(labels_pred)):\n","        if labels_pred[i] == labels_true[i]:\n","            scores+=1\n","    return(scores/len(labels_pred))\n","\n","def predict(models, X_test, y_test):\n","    \"\"\"\n","    Uses the built models to predict class labels of test instances. The \"left or right hand\" versus \"tongue or foot\" classifier is first invoked. The decision of this classifier indicates which level 2 classifier to invoke.\n","    If the level 1 classifier predicts \"left or right hand\" then the left hand verus right hand level 2 classifier is invoked. Else, the tongue versus foot level 2 classifier is invoked.\n","\n","    Parameters:\n","    models(dict): dictionary of all models\n","    X_test(numpy.ndarray): the test instances\n","    y_test(numpy.ndarrat): the labels corresponding to the test set\n","\n","    Returns:\n","    float: the prediction accuracy of the model\n","    float: the cohen kappa score of the model\n","    np.ndarray: the average precision, recall and f1 scores of the model\n","    \"\"\"\n","\n","    X_test = reshape_trial_major(X_test)\n","    pred = []\n","    start = time.time()\n","    for i in range(len(y_test)):\n","        clf_LRvsTF = models['LRvsTF']\n","        sample_LRvsTF = get_test_features(X_test[i], clf_LRvsTF['W'], clf_LRvsTF['a'])\n","        pred_LRvsTF = clf_LRvsTF['clf'].predict([sample_LRvsTF])[0]\n","\n","        if pred_LRvsTF == 0:\n","            clf_LR = models['LR']\n","            sample_LR = get_test_features(X_test[i], clf_LR['W'], clf_LR['a'])\n","            pred_LR = clf_LR['clf'].predict([sample_LR])[0]\n","            pred_LR = 769 if pred_LR == 0 else 770\n","            pred.append(pred_LR)\n","\n","        else:\n","            clf_TF = models['TF']\n","            sample_TF = get_test_features(X_test[i], clf_TF['W'], clf_TF['a'])\n","            pred_TF = clf_TF['clf'].predict([sample_TF])[0]\n","            pred_TF = 771 if pred_TF == 0 else 772\n","            pred.append(pred_TF)\n","    end = time.time() - start\n","    return score(pred, y_test), cohen_kappa_score(pred, y_test), end/len(y_test), np.mean(precision_recall_fscore_support(y_test, pred)[0]), np.mean(precision_recall_fscore_support(y_test, pred)[1]), np.mean(precision_recall_fscore_support(y_test, pred)[2])"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zEA0FZa8CIwT"},"source":["Builds the classifiers and evaluates them on each subjects data. The parameter values used for the XGBoost classifiers -\n","\n","\n","*   Max depth - 8\n","*   Number of Estimator - 500\n","*   Column Subsampling Ratio - 0.5\n"]},{"cell_type":"code","metadata":{"id":"6313iOlRb7lb","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1593457083035,"user_tz":-330,"elapsed":176517,"user":{"displayName":"Malaika Vijay 01FB16ECS189PESU CSESTUDENT","photoUrl":"","userId":"09943993467447951085"}},"outputId":"f08dd10e-a0ed-41de-a27c-033eafc7486c"},"source":["kappas = []\n","accs = []\n","p = []\n","r = []\n","f = []\n","for subject in range(1,10):\n","  models, X_test, y_test = build_classifiers(subject, 0.01, 8, 500, 0.5)\n","  acc, kappa, test_time, precision, recall, f1 = predict_one_vs_one(models, X_test, y_test)\n","  accs.append(acc)\n","  kappas.append(kappa)\n","  p.append(precision)\n","  r.append(recall)\n","  f.append(f1)\n","  print(subject, kappa, acc, precision, recall, f1)\n","  \n","print(\"kappa: \", np.mean(kappas), \"accs: \",np.mean(accs), \"precision: \", np.mean(p), \"recall: \", np.mean(recall), \"f1: \", np.mean(f))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 0.7685185185185185 0.8263888888888888 0.8442493169559329 0.8263888888888888 0.8250613991600708\n","2 0.43981481481481477 0.5798611111111112 0.5803960911822486 0.579861111111111 0.5674835902822569\n","3 0.7314814814814814 0.7986111111111112 0.8048105582941649 0.7986111111111112 0.7950489521168838\n","4 0.4722222222222222 0.6041666666666666 0.670702902719483 0.6041666666666666 0.5801048357628964\n","5 0.3194444444444444 0.4895833333333333 0.5186104574413132 0.4895833333333333 0.39948227414897697\n","6 0.20833333333333337 0.40625 0.46757362736701874 0.40625 0.3810042749059739\n","7 0.7962962962962963 0.8472222222222222 0.8552816352004993 0.8472222222222222 0.847032967032967\n","8 0.6527777777777778 0.7395833333333334 0.7651046147707578 0.7395833333333333 0.7384933041938542\n","9 0.37962962962962965 0.5347222222222222 0.6601779422128259 0.5347222222222222 0.5023845635321874\n","kappa:  0.5298353909465021 accs:  0.6473765432098765 precision:  0.6852119051271381 recall:  0.5347222222222222 f1:  0.6262329067928962\n"],"name":"stdout"}]}]}